#!/bin/bash -l
# This script focuses on using GPU, but there are more examples on requesting other resources below
# https://pawsey.atlassian.net/wiki/spaces/US/pages/51925964/Job+Scheduling#JobScheduling-SubmittingajobtoSlurm
#SBATCH --account=pawsey1157
#SBATCH --partition=work
#SBATCH --ntasks=1
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=8
#SBATCH --mem=1GB
#SBATCH --time=01:00:00
#SBATCH --job-name=lncRdiscovery
#SBATCH --export=NONE
 
# Set the JUPYTER working directory where you can save your notebooks. Might be the same as the Github repo for the project.
jupyterDir="/software/projects/pawsey1157/modanilevicz/setonix/GitHub"
pythonEnv="/software/projects/pawsey1157/modanilevicz/setonix/pythonEnvironments/tensorflowContainer_env/machinelearning/bin/activate"
 
# Get the hostname. We'll set up an SSH tunnel to connect to the Juypter notebook server
host=$(hostname)
port="8888"
 
# Load Tensorflow or any other modules you need to run within the notebook
module load tensorflow/rocm5.6-tf2.12 
export OMP_NUM_THREADS=1

# once the slurm script is running, open the output and read the instructions below
# which will have the updated node number and port connected.

echo "*****************************************************"
echo "Setup - Open a new terminal windowfrom your laptop:"
echo "ssh -N -f -L ${port}:${host}:${port} $USER@$PAWSEY_CLUSTER.pawsey.org.au"
echo "*****"
echo "The launch directory is: $jupyterDir"
echo "*****************************************************"
echo ""
echo "*****************************************************"
echo "Terminate - from your laptop do:"
echo "kill \$( ps x | grep 'ssh.*-L *${port}:${host}:${port}' | awk '{print \$1}' )"
echo "*****************************************************"
echo ""
  
srun -N 1 -n 1 -c 8  bash -c \
	"source $pythonEnv && jupyter notebook  --no-browser  --port=${port} --ip=0.0.0.0  --notebook-dir=${jupyterDir}"
